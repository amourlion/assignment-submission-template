# å¤šèŠ‚ç‚¹ç›‘æµ‹ä½¿ç”¨æ–¹æ¡ˆ

æœ¬æ–‡æ¡£æä¾›äº†åœ¨Hadoopé›†ç¾¤å¤šä¸ªèŠ‚ç‚¹ä¸Šéƒ¨ç½²æ€§èƒ½ç›‘æµ‹è„šæœ¬å¹¶è¿è¡Œæ‰¹é‡å®éªŒçš„å®Œæ•´æ“ä½œæŒ‡å—ã€‚

## ğŸ“‹ æ‰§è¡Œæ–¹æ¡ˆæ¦‚è¿°

æœ¬æ–¹æ¡ˆåŒ…å«ä»¥ä¸‹ä¸»è¦æ­¥éª¤:
1. HDFSæ•°æ®å‡†å¤‡
2. æ¸…ç†æœ¬åœ°å®éªŒæ•°æ®
3. åœ¨è¿œç¨‹èŠ‚ç‚¹éƒ¨ç½²ç›‘æµ‹è„šæœ¬
4. ä¿®æ”¹æ‰¹é‡å®éªŒé…ç½®
5. æ‰§è¡Œæ‰¹é‡å®éªŒ
6. æ”¶é›†å’Œåˆå¹¶ç›‘æµ‹æ•°æ®

---

## ğŸš€ å®Œæ•´æ‰§è¡Œæµç¨‹

### **é˜¶æ®µ1: å‡†å¤‡å·¥ä½œ**
#### 1.1 å®éªŒæ•°æ®å‡†å¤‡

#### 1.2 æ¸…ç†æœ¬åœ°å®éªŒæ•°æ®
```bash
# æ¸…ç†ä¹‹å‰çš„å®éªŒç»“æœæ•°æ®
rm -rf metrics/*

# æ¸…ç†ä¹‹å‰çš„ç³»ç»Ÿç›‘æµ‹æ•°æ®
rm -rf system_metrics/*
```

---

### **é˜¶æ®µ2: éƒ¨ç½²è¿œç¨‹ç›‘æµ‹è„šæœ¬**

#### 2.1 åœ¨hadoop002èŠ‚ç‚¹éƒ¨ç½²
```bash
# æ­¥éª¤1: åˆ›å»ºè¿œç¨‹ç›‘æµ‹ç›®å½•
ssh hadoop002 "mkdir -p ~/monitoring"

# æ­¥éª¤2: æ‹·è´ç›‘æµ‹è„šæœ¬åˆ°hadoop002
scp scripts/collect_metrics.sh hadoop002:~/monitoring/

# æ­¥éª¤3: éªŒè¯è„šæœ¬å·²æˆåŠŸæ‹·è´
ssh hadoop002 "ls -lh ~/monitoring/"
```

#### 2.2 åœ¨hadoop003èŠ‚ç‚¹éƒ¨ç½²
```bash
# æ­¥éª¤1: åˆ›å»ºè¿œç¨‹ç›‘æµ‹ç›®å½•
ssh hadoop003 "mkdir -p ~/monitoring"

# æ­¥éª¤2: æ‹·è´ç›‘æµ‹è„šæœ¬åˆ°hadoop003
scp scripts/collect_metrics.sh hadoop003:~/monitoring/

# æ­¥éª¤3: éªŒè¯è„šæœ¬å·²æˆåŠŸæ‹·è´
ssh hadoop003 "ls -lh ~/monitoring/"
```

#### 2.3 å¯åŠ¨è¿œç¨‹èŠ‚ç‚¹ç›‘æµ‹
```bash
# å¯åŠ¨hadoop002ç›‘æµ‹ (é‡‡é›†é—´éš”1ç§’)
ssh hadoop002 "cd ~/monitoring && nohup ./collect_metrics.sh hadoop002 1 > /dev/null 2>&1 &"

# å¯åŠ¨hadoop003ç›‘æµ‹ (é‡‡é›†é—´éš”1ç§’)
ssh hadoop003 "cd ~/monitoring && nohup ./collect_metrics.sh hadoop003 1 > /dev/null 2>&1 &"

# éªŒè¯ç›‘æµ‹è¿›ç¨‹å·²å¯åŠ¨
ssh hadoop002 "ps aux | grep collect_metrics"
ssh hadoop003 "ps aux | grep collect_metrics"
```

**è¾“å‡ºæ–‡ä»¶ä½ç½®:**
- hadoop002: `~/monitoring/hadoop002.csv`
- hadoop003: `~/monitoring/hadoop003.csv`

---

### **é˜¶æ®µ3: ä¿®æ”¹æ‰¹é‡å®éªŒé…ç½®**

ä¿®æ”¹ `scripts/batch_experiment.sh` æ–‡ä»¶ä¸­çš„slowstartå‚æ•°é…ç½®:

```bash
# æ‰¾åˆ°ä»¥ä¸‹è¡Œ:
SLOWSTART_VALUES=(0.1 0.3 0.5 0.7 1.0)

# ä¿®æ”¹ä¸º:
SLOWSTART_VALUES=(0.1 0.3 0.5 0.7 0.9)
```

**ä¿®æ”¹æ–¹æ³•:**
```bash
# ä½¿ç”¨sedå‘½ä»¤ç›´æ¥ä¿®æ”¹
sed -i 's/SLOWSTART_VALUES=(0.1 0.3 0.5 0.7 1.0)/SLOWSTART_VALUES=(0.1 0.3 0.5 0.7 0.9)/' scripts/batch_experiment.sh

# éªŒè¯ä¿®æ”¹
grep "SLOWSTART_VALUES" scripts/batch_experiment.sh
```

---

### **é˜¶æ®µ4: è¿è¡Œæ‰¹é‡å®éªŒ**

```bash
# æ‰§è¡Œæ‰¹é‡å®éªŒ
# å‚æ•°1: HDFSè¾“å…¥è·¯å¾„
# å‚æ•°2: HDFSè¾“å‡ºè·¯å¾„åŸºç¡€å
./scripts/batch_experiment.sh /mr_input_5gb /mr_output
```

**å®éªŒè¯´æ˜:**
- å°†è‡ªåŠ¨è¿è¡Œ5ç»„å®éªŒ,slowstartå‚æ•°åˆ†åˆ«ä¸º: 0.1, 0.3, 0.5, 0.7, 0.9
- æ¯ç»„å®éªŒä¹‹é—´æœ‰10ç§’é—´éš”
- æ¯ç»„å®éªŒçš„è¾“å‡ºè·¯å¾„ä¸º: `/mr_output_slowstart_01`, `/mr_output_slowstart_03`, ç­‰
- å®éªŒè¿‡ç¨‹ä¸­,è¿œç¨‹èŠ‚ç‚¹çš„ç›‘æµ‹è„šæœ¬ä¼šæŒç»­æ”¶é›†ç³»ç»Ÿæ€§èƒ½æ•°æ®

**é¢„æœŸè¾“å‡º:**
```
=== Hadoop MapReduce Batch Experiment ===
Input Path: /mr_input_5gb
Output Base Path: /mr_output
Experiment Base ID: batch_20251126_112605
Slowstart Values: 0.1 0.3 0.5 0.7 0.9

Starting batch experiments...

--- Experiment 1/5: slowstart=0.1 ---
...
âœ“ Experiment 1 completed successfully in XXXs

--- Experiment 2/5: slowstart=0.3 ---
...
```

---

### **é˜¶æ®µ5: å®éªŒå®Œæˆåæ”¶é›†æ•°æ®**

#### 5.1 åœæ­¢è¿œç¨‹ç›‘æµ‹
```bash
# åœæ­¢hadoop002ç›‘æµ‹è¿›ç¨‹
ssh hadoop002 "pkill -f 'collect_metrics.sh hadoop002'"

# åœæ­¢hadoop003ç›‘æµ‹è¿›ç¨‹
ssh hadoop003 "pkill -f 'collect_metrics.sh hadoop003'"

# éªŒè¯è¿›ç¨‹å·²åœæ­¢
ssh hadoop002 "ps aux | grep collect_metrics"
ssh hadoop003 "ps aux | grep collect_metrics"
```

#### 5.2 æ”¶é›†è¿œç¨‹èŠ‚ç‚¹æ•°æ®
```bash
# ä»hadoop002æ”¶é›†CSVæ–‡ä»¶åˆ°æœ¬åœ°system_metricsç›®å½•
scp hadoop002:~/monitoring/hadoop002.csv ./system_metrics/

# ä»hadoop003æ”¶é›†CSVæ–‡ä»¶åˆ°æœ¬åœ°system_metricsç›®å½•
scp hadoop003:~/monitoring/hadoop003.csv ./system_metrics/

# éªŒè¯æ–‡ä»¶å·²æˆåŠŸæ”¶é›†
ls -lh ./system_metrics/
```

#### 5.3 åˆå¹¶æ‰€æœ‰èŠ‚ç‚¹æ•°æ® (å¯é€‰)
```bash
# å°†æ‰€æœ‰èŠ‚ç‚¹çš„ç›‘æµ‹æ•°æ®åˆå¹¶æˆä¸€ä¸ªCSVæ–‡ä»¶
./scripts/merge_node_metrics.sh \
    system_metrics/cluster_merged.csv \
    system_metrics/hadoop002.csv \
    system_metrics/hadoop003.csv

# æŸ¥çœ‹åˆå¹¶åçš„æ•°æ®
head -n 10 system_metrics/cluster_merged.csv
```

---

## ğŸ“ ç›®å½•ç»“æ„

### è¿œç¨‹èŠ‚ç‚¹ (hadoop002/hadoop003)
```
~/monitoring/
  â”œâ”€â”€ collect_metrics.sh      # æ€§èƒ½ç›‘æµ‹è„šæœ¬
  â”œâ”€â”€ hadoop002.csv           # hadoop002çš„ç›‘æµ‹æ•°æ®
  â””â”€â”€ hadoop003.csv           # hadoop003çš„ç›‘æµ‹æ•°æ®
```

### æœ¬åœ°èŠ‚ç‚¹
```
/home/ecs-user/MRApplication/reduce-startup/
  â”œâ”€â”€ metrics/                           # æ‰¹é‡å®éªŒç»“æœæ•°æ®
  â”‚   â”œâ”€â”€ batch_summary_*.csv           # å®éªŒæ±‡æ€»æ•°æ®
  â”‚   â”œâ”€â”€ analysis_report_*.txt         # è‡ªåŠ¨ç”Ÿæˆçš„åˆ†ææŠ¥å‘Š
  â”‚   â””â”€â”€ experiment_*_timeline_*.csv   # å„ä¸ªå®éªŒçš„æ—¶é—´çº¿æ•°æ®
  â”‚
  â””â”€â”€ system_metrics/                    # ç³»ç»Ÿæ€§èƒ½ç›‘æµ‹æ•°æ®
      â”œâ”€â”€ hadoop002.csv                  # hadoop002èŠ‚ç‚¹æ•°æ®
      â”œâ”€â”€ hadoop003.csv                  # hadoop003èŠ‚ç‚¹æ•°æ®
      â””â”€â”€ cluster_merged.csv             # åˆå¹¶åçš„é›†ç¾¤æ•°æ®
```

---

## ğŸ“Š æ•°æ®æ–‡ä»¶è¯´æ˜

### å®éªŒç»“æœæ•°æ® (metrics/)

**æ‰¹é‡å®éªŒæ±‡æ€»æ–‡ä»¶:** `batch_summary_*.csv`
```csv
experiment_id,slowstart_value,start_time,end_time,total_time_sec,avg_cpu_percent,max_cpu_percent,avg_memory_mb,max_memory_mb,avg_load,max_load,bytes_read,bytes_written,map_tasks,reduce_tasks,job_status
```

**åˆ†ææŠ¥å‘Šæ–‡ä»¶:** `analysis_report_*.txt`
- åŒ…å«æ‰€æœ‰å®éªŒçš„æ€§èƒ½åˆ†æ
- slowstartå‚æ•°å¯¹æ¯”
- æœ€ä¼˜é…ç½®æ¨è

### ç³»ç»Ÿç›‘æµ‹æ•°æ® (system_metrics/)

**èŠ‚ç‚¹ç›‘æµ‹æ–‡ä»¶:** `hadoop002.csv`, `hadoop003.csv`
```csv
node_name,timestamp,cpu_percent,memory_used_mb,memory_total_mb,memory_percent,load_avg,disk_reads,disk_writes,network_rx_mb,network_tx_mb,java_cpu_percent,java_memory_percent,java_processes
```

**åˆ—è¯´æ˜:**
- `node_name`: èŠ‚ç‚¹åç§°
- `timestamp`: Unixæ—¶é—´æˆ³
- `cpu_percent`: CPUä½¿ç”¨ç‡ç™¾åˆ†æ¯”
- `memory_used_mb`: å·²ä½¿ç”¨å†…å­˜(MB)
- `memory_total_mb`: æ€»å†…å­˜(MB)
- `memory_percent`: å†…å­˜ä½¿ç”¨ç‡ç™¾åˆ†æ¯”
- `load_avg`: ç³»ç»Ÿå¹³å‡è´Ÿè½½
- `disk_reads`: ç£ç›˜è¯»å–æ¬¡æ•°
- `disk_writes`: ç£ç›˜å†™å…¥æ¬¡æ•°
- `network_rx_mb`: ç½‘ç»œæ¥æ”¶æµé‡(MB)
- `network_tx_mb`: ç½‘ç»œå‘é€æµé‡(MB)
- `java_cpu_percent`: Javaè¿›ç¨‹CPUä½¿ç”¨ç‡
- `java_memory_percent`: Javaè¿›ç¨‹å†…å­˜ä½¿ç”¨ç‡
- `java_processes`: Javaè¿›ç¨‹æ•°é‡

---

## âš ï¸ é‡è¦æ³¨æ„äº‹é¡¹

### 1. SSHå…å¯†ç™»å½•é…ç½®
ç¡®ä¿å½“å‰èŠ‚ç‚¹å¯ä»¥æ— å¯†ç SSHåˆ°hadoop002å’Œhadoop003:
```bash
# ç”ŸæˆSSHå¯†é’¥(å¦‚æœè¿˜æ²¡æœ‰)
ssh-keygen -t rsa -b 4096

# å°†å…¬é’¥å¤åˆ¶åˆ°è¿œç¨‹èŠ‚ç‚¹
ssh-copy-id hadoop002
ssh-copy-id hadoop003

# æµ‹è¯•å…å¯†ç™»å½•
ssh hadoop002 "echo 'SSHè¿æ¥æˆåŠŸ'"
ssh hadoop003 "echo 'SSHè¿æ¥æˆåŠŸ'"
```

### 2. ç£ç›˜ç©ºé—´æ£€æŸ¥
```bash
# æ£€æŸ¥æœ¬åœ°ç£ç›˜ç©ºé—´
df -h .

# æ£€æŸ¥è¿œç¨‹èŠ‚ç‚¹ç£ç›˜ç©ºé—´
ssh hadoop002 "df -h ~"
ssh hadoop003 "df -h ~"

# æ£€æŸ¥HDFSç©ºé—´
hdfs dfs -df -h
```

### 3. æ—¶é—´åŒæ­¥
ç¡®ä¿æ‰€æœ‰èŠ‚ç‚¹æ—¶é—´åŒæ­¥,ä¾¿äºæ•°æ®åˆ†æ:
```bash
# æ£€æŸ¥å„èŠ‚ç‚¹æ—¶é—´
date
ssh hadoop002 "date"
ssh hadoop003 "date"
```

### 4. å®éªŒæ—¶é—´ä¼°ç®—
- 5GBæ•°æ® Ã— 5ç»„å®éªŒ â‰ˆ é¢„è®¡æ€»æ—¶é—´è¾ƒé•¿
- æ¯ç»„å®éªŒé—´éš”10ç§’
- å»ºè®®åœ¨ç©ºé—²æ—¶æ®µè¿è¡Œ

### 5. è¿›ç¨‹ç®¡ç†
å®éªŒç»“æŸååŠ¡å¿…åœæ­¢æ‰€æœ‰ç›‘æµ‹è¿›ç¨‹,é¿å…:
- æŒç»­å ç”¨CPU/å†…å­˜èµ„æº
- ç”Ÿæˆå¤§é‡æ—¥å¿—æ–‡ä»¶å ç”¨ç£ç›˜ç©ºé—´

---

## ğŸ› ï¸ å¸¸ç”¨å‘½ä»¤é€ŸæŸ¥

### æ£€æŸ¥ç›‘æµ‹è¿›ç¨‹çŠ¶æ€
```bash
# æ£€æŸ¥æ‰€æœ‰èŠ‚ç‚¹çš„ç›‘æµ‹è¿›ç¨‹
for node in hadoop002 hadoop003; do
    echo "=== $node ==="
    ssh $node "ps aux | grep collect_metrics | grep -v grep"
done
```

### å®æ—¶æŸ¥çœ‹ç›‘æµ‹æ•°æ®
```bash
# æŸ¥çœ‹hadoop002æœ€æ–°æ•°æ®
ssh hadoop002 "tail -f ~/monitoring/hadoop002.csv"

# æŸ¥çœ‹hadoop003æœ€æ–°æ•°æ®
ssh hadoop003 "tail -f ~/monitoring/hadoop003.csv"
```

### æ¸…ç†è¿œç¨‹ç›‘æµ‹æ•°æ®
```bash
# æ¸…ç†hadoop002ç›‘æµ‹æ•°æ®
ssh hadoop002 "rm -rf ~/monitoring/*.csv"

# æ¸…ç†hadoop003ç›‘æµ‹æ•°æ®
ssh hadoop003 "rm -rf ~/monitoring/*.csv"
```

### æ‰¹é‡åœæ­¢æ‰€æœ‰ç›‘æµ‹
```bash
# ä¸€é”®åœæ­¢æ‰€æœ‰èŠ‚ç‚¹ç›‘æµ‹
for node in hadoop002 hadoop003; do
    ssh $node "pkill -f collect_metrics"
    echo "$node ç›‘æµ‹å·²åœæ­¢"
done
```

---

## ğŸ¯ æœ€ä½³å®è·µå»ºè®®

1. **å®éªŒå‰æ£€æŸ¥æ¸…å•**
   - [ ] HDFSè¾“å…¥æ•°æ®å·²å‡†å¤‡
   - [ ] æœ¬åœ°ç£ç›˜ç©ºé—´å……è¶³
   - [ ] SSHå…å¯†ç™»å½•é…ç½®å®Œæˆ
   - [ ] æ‰€æœ‰èŠ‚ç‚¹æ—¶é—´å·²åŒæ­¥
   - [ ] ä¹‹å‰çš„å®éªŒæ•°æ®å·²å¤‡ä»½æˆ–æ¸…ç†

2. **å®éªŒä¸­ç›‘æ§**
   - å®šæœŸæ£€æŸ¥ç›‘æµ‹è¿›ç¨‹æ˜¯å¦æ­£å¸¸è¿è¡Œ
   - ç›‘æ§ç£ç›˜ç©ºé—´ä½¿ç”¨æƒ…å†µ
   - å…³æ³¨å®éªŒæ—¥å¿—è¾“å‡º

3. **å®éªŒåå¤„ç†**
   - åŠæ—¶åœæ­¢æ‰€æœ‰ç›‘æµ‹è¿›ç¨‹
   - æ”¶é›†å¹¶å¤‡ä»½é‡è¦æ•°æ®
   - ç”Ÿæˆå®éªŒæŠ¥å‘Šå’Œå¯è§†åŒ–å›¾è¡¨
   - æ¸…ç†ä¸éœ€è¦çš„ä¸´æ—¶æ–‡ä»¶

4. **æ•°æ®ç®¡ç†**
   - ä½¿ç”¨æ—¶é—´æˆ³å‘½åå®éªŒæ•°æ®
   - å®šæœŸå¤‡ä»½é‡è¦å®éªŒç»“æœ
   - å»ºç«‹å®éªŒæ—¥å¿—è®°å½•ä¹ æƒ¯

---

## ğŸ“ˆ æ•°æ®åˆ†æç¤ºä¾‹

### ä½¿ç”¨awkåˆ†æèŠ‚ç‚¹æ€§èƒ½
```bash
# è®¡ç®—hadoop002çš„å¹³å‡CPUä½¿ç”¨ç‡
awk -F',' 'NR>1 {sum+=$3; count++} END {print "å¹³å‡CPU:", sum/count"%"}' \
    system_metrics/hadoop002.csv

# æ‰¾å‡ºhadoop003çš„æœ€å¤§å†…å­˜ä½¿ç”¨
awk -F',' 'NR>1 {if($4>max) max=$4} END {print "æœ€å¤§å†…å­˜:", max"MB"}' \
    system_metrics/hadoop003.csv
```

### å¯¼å…¥Pythonè¿›è¡Œåˆ†æ
```python
import pandas as pd

# è¯»å–åˆå¹¶åçš„é›†ç¾¤æ•°æ®
df = pd.read_csv('system_metrics/cluster_merged.csv')

# æŒ‰èŠ‚ç‚¹åˆ†ç»„ç»Ÿè®¡
stats = df.groupby('node_name').agg({
    'cpu_percent': ['mean', 'max'],
    'memory_percent': ['mean', 'max'],
    'load_avg': 'mean'
})

print(stats)
```

---

## ğŸ†˜ æ•…éšœæ’é™¤

### é—®é¢˜1: SSHè¿æ¥å¤±è´¥
```bash
# è§£å†³æ–¹æ¡ˆ: æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒSSHé…ç½®
ping hadoop002
ssh -v hadoop002
```

### é—®é¢˜2: ç›‘æµ‹è„šæœ¬æ— æ³•æ‰§è¡Œ
```bash
# è§£å†³æ–¹æ¡ˆ: æ£€æŸ¥è„šæœ¬æƒé™
ssh hadoop002 "chmod +x ~/monitoring/collect_metrics.sh"
```

### é—®é¢˜3: ç£ç›˜ç©ºé—´ä¸è¶³
```bash
# è§£å†³æ–¹æ¡ˆ: æ¸…ç†æ—§æ•°æ®æˆ–æ‰©å±•ç£ç›˜
ssh hadoop002 "du -sh ~/monitoring/*"
ssh hadoop002 "rm -rf ~/monitoring/*.csv.old"
```

### é—®é¢˜4: æ•°æ®æ”¶é›†å¤±è´¥
```bash
# è§£å†³æ–¹æ¡ˆ: æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
ssh hadoop002 "ls -lh ~/monitoring/"
ssh hadoop002 "tail ~/monitoring/hadoop002.csv"
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [MULTI_NODE_USAGE.md](./MULTI_NODE_USAGE.md) - å¤šèŠ‚ç‚¹æ€§èƒ½ç›‘æµ‹åŸºç¡€æ–‡æ¡£
- [README.md](../readme.md) - é¡¹ç›®ä¸»æ–‡æ¡£
- [visualization/README.md](../visualization/README.md) - æ•°æ®å¯è§†åŒ–æ–‡æ¡£

---

**æœ€åæ›´æ–°:** 2025-11-26
**ç»´æŠ¤è€…:** Hadoopå®éªŒå›¢é˜Ÿ
