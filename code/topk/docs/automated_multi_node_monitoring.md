# è‡ªåŠ¨åŒ–å¤šèŠ‚ç‚¹ç›‘æ§ä½¿ç”¨æŒ‡å—

æœ¬æ–‡æ¡£è¯´æ˜å¦‚ä½•ä½¿ç”¨é›†æˆäº†è‡ªåŠ¨åŒ–å¤šèŠ‚ç‚¹ç›‘æ§åŠŸèƒ½çš„æ‰¹é‡å®éªŒè„šæœ¬ã€‚

## ğŸ“‹ åŠŸèƒ½æ¦‚è¿°

å¢å¼ºç‰ˆçš„ `batch_experiment.sh` ç°åœ¨æ”¯æŒï¼š

1. **è‡ªåŠ¨éƒ¨ç½²**ï¼šè‡ªåŠ¨å°†ç›‘æ§è„šæœ¬éƒ¨ç½²åˆ°è¿œç¨‹èŠ‚ç‚¹
2. **è‡ªåŠ¨å¯åŠ¨**ï¼šå®éªŒå¼€å§‹å‰è‡ªåŠ¨å¯åŠ¨æ‰€æœ‰èŠ‚ç‚¹çš„ç›‘æ§è¿›ç¨‹
3. **è‡ªåŠ¨ç»ˆæ­¢**ï¼šå®éªŒç»“æŸåè‡ªåŠ¨åœæ­¢æ‰€æœ‰ç›‘æ§è¿›ç¨‹
4. **è‡ªåŠ¨å›ä¼ **ï¼šè‡ªåŠ¨ä»è¿œç¨‹èŠ‚ç‚¹æ”¶é›†ç›‘æ§æ•°æ®åˆ°æœ¬åœ°

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å‰ææ¡ä»¶

ç¡®ä¿å·²é…ç½® SSH å…å¯†ç ç™»å½•ï¼š

```bash
# æµ‹è¯• SSH è¿æ¥
ssh hadoop002 "echo 'Connection successful'"
ssh hadoop003 "echo 'Connection successful'"
```

### ä¸€é”®æ‰§è¡Œ

ç°åœ¨åªéœ€ä¸€ä¸ªå‘½ä»¤å³å¯å®Œæˆæ‰€æœ‰æ“ä½œï¼š

```bash
# æ‰§è¡Œæ‰¹é‡å®éªŒï¼ˆè‡ªåŠ¨å®Œæˆç›‘æ§éƒ¨ç½²ã€å¯åŠ¨ã€æ•°æ®æ”¶é›†ï¼‰
./scripts/batch_experiment.sh /mr_input_5gb /mr_output
```

## ğŸ”§ é…ç½®è¯´æ˜

### è¿œç¨‹èŠ‚ç‚¹é…ç½®

åœ¨ `scripts/batch_experiment.sh` ä¸­ä¿®æ”¹ä»¥ä¸‹é…ç½®ï¼š

```bash
# è¦ç›‘æ§çš„è¿œç¨‹èŠ‚ç‚¹åˆ—è¡¨
REMOTE_NODES=("hadoop002" "hadoop003")

# è¿œç¨‹ç›‘æ§ç›®å½•
REMOTE_MONITOR_DIR="~/monitoring"

# ç›‘æ§æ•°æ®é‡‡é›†é—´éš”ï¼ˆç§’ï¼‰
MONITOR_INTERVAL=1

# æœ¬åœ°æ•°æ®å­˜å‚¨ç›®å½•
LOCAL_METRICS_DIR="system_metrics"
```

### æ·»åŠ æ›´å¤šèŠ‚ç‚¹

```bash
# ä¿®æ”¹èŠ‚ç‚¹åˆ—è¡¨
REMOTE_NODES=("hadoop002" "hadoop003" "hadoop004" "hadoop005")
```

## ğŸ“Š æ‰§è¡Œæµç¨‹

è„šæœ¬ä¼šæŒ‰ä»¥ä¸‹å››ä¸ªé˜¶æ®µè‡ªåŠ¨æ‰§è¡Œï¼š

### Phase 1: Multi-Node Monitoring Setup
```
â†’ ä¸ºæ¯ä¸ªè¿œç¨‹èŠ‚ç‚¹åˆ›å»ºç›‘æ§ç›®å½•
â†’ éƒ¨ç½² collect_metrics.sh åˆ°è¿œç¨‹èŠ‚ç‚¹
â†’ å¯åŠ¨è¿œç¨‹ç›‘æ§è¿›ç¨‹
â†’ éªŒè¯ç›‘æ§è¿›ç¨‹çŠ¶æ€
```

### Phase 2: Batch Experiments
```
â†’ æ‰§è¡Œæ‰¹é‡ MapReduce å®éªŒ
â†’ è¿œç¨‹ç›‘æ§æŒç»­æ”¶é›†æ•°æ®
â†’ ç”Ÿæˆå®éªŒç»“æœæŠ¥å‘Š
```

### Phase 3: Stop Monitoring and Collect Data
```
â†’ åœæ­¢æ‰€æœ‰è¿œç¨‹ç›‘æ§è¿›ç¨‹
â†’ ä»è¿œç¨‹èŠ‚ç‚¹æ”¶é›† CSV æ•°æ®æ–‡ä»¶
â†’ ä¿å­˜åˆ°æœ¬åœ° system_metrics/ ç›®å½•
```

### Phase 4: Analysis and Reporting
```
â†’ ç”Ÿæˆå®éªŒåˆ†ææŠ¥å‘Š
â†’ æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡æ±‡æ€»
â†’ åˆ—å‡ºæ”¶é›†çš„ç›‘æ§æ•°æ®æ–‡ä»¶
```

## ğŸ“ è¾“å‡ºæ–‡ä»¶ç»“æ„

æ‰§è¡Œå®Œæˆåï¼Œæ–‡ä»¶ç»„ç»‡å¦‚ä¸‹ï¼š

```
/home/ecs-user/MRApplication/reduce-startup/
â”œâ”€â”€ metrics/                                    # å®éªŒç»“æœ
â”‚   â”œâ”€â”€ batch_summary_batch_20251126_*.csv     # æ‰¹é‡å®éªŒæ±‡æ€»
â”‚   â”œâ”€â”€ analysis_report_batch_20251126_*.txt   # åˆ†ææŠ¥å‘Š
â”‚   â””â”€â”€ experiment_*_slowstart_*.csv           # å„å®éªŒè¯¦ç»†æ•°æ®
â”‚
â””â”€â”€ system_metrics/                             # ç›‘æ§æ•°æ®
    â”œâ”€â”€ hadoop002_20251126_*.csv               # hadoop002 ç›‘æ§æ•°æ®
    â””â”€â”€ hadoop003_20251126_*.csv               # hadoop003 ç›‘æ§æ•°æ®
```

## ğŸ’¡ ç¤ºä¾‹è¾“å‡º

### æˆåŠŸæ‰§è¡Œç¤ºä¾‹

```
=== Hadoop MapReduce Batch Experiment with Multi-Node Monitoring ===
Input Path: /mr_input_5gb
Output Base Path: /mr_output
Experiment Base ID: batch_20251126_130215
Slowstart Values: 0.1 0.3 0.5 0.7 1.0
Remote Nodes: hadoop002 hadoop003

=== Phase 1: Multi-Node Monitoring Setup ===

Setting up monitoring on hadoop002:
  â†’ Deploying monitoring script to hadoop002...
  âœ“ Successfully deployed to hadoop002
  â†’ Starting monitoring on hadoop002...
  âœ“ Monitoring started on hadoop002 (PID: 12345)

Setting up monitoring on hadoop003:
  â†’ Deploying monitoring script to hadoop003...
  âœ“ Successfully deployed to hadoop003
  â†’ Starting monitoring on hadoop003...
  âœ“ Monitoring started on hadoop003 (PID: 23456)

Monitoring Setup Summary:
  Deployed: 2/2 nodes
  Started: 2/2 nodes
âœ“ Monitoring is active on 2 node(s)

=== Phase 2: Batch Experiments ===
Starting batch experiments...

--- Experiment 1/5: slowstart=0.1 ---
...

=== Phase 3: Stop Monitoring and Collect Data ===

Processing hadoop002:
  â†’ Stopping monitoring on hadoop002...
  âœ“ Monitoring stopped on hadoop002
  â†’ Collecting data from hadoop002...
  âœ“ Collected hadoop002_20251126_130215.csv (2.3M) from hadoop002

Processing hadoop003:
  â†’ Stopping monitoring on hadoop003...
  âœ“ Monitoring stopped on hadoop003
  â†’ Collecting data from hadoop003...
  âœ“ Collected hadoop003_20251126_130215.csv (2.1M) from hadoop003

Data Collection Summary:
  Stopped: 2/2 nodes
  Collected: 2/2 nodes

âœ“ Successfully collected monitoring data from 2 node(s):
  hadoop002: system_metrics/hadoop002_20251126_130215.csv
  hadoop003: system_metrics/hadoop003_20251126_130215.csv

=== Phase 4: Analysis and Reporting ===

=== Batch Experiment Summary ===
Total Experiments: 5
Successful: 5
Failed: 0
Total Batch Time: 1234 seconds

=== Collected Monitoring Data ===
Node        | File Location
------------|--------------------------------------------
hadoop002   | system_metrics/hadoop002_20251126_130215.csv
hadoop003   | system_metrics/hadoop003_20251126_130215.csv

All tasks completed successfully!
```

## âš ï¸ å®¹é”™æœºåˆ¶

è„šæœ¬åŒ…å«å®Œå–„çš„å®¹é”™å¤„ç†ï¼š

### èŠ‚ç‚¹éƒ¨ç½²å¤±è´¥
- è‡ªåŠ¨è·³è¿‡å¤±è´¥çš„èŠ‚ç‚¹
- ç»§ç»­å¤„ç†å…¶ä»–èŠ‚ç‚¹
- æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯

### ç›‘æ§å¯åŠ¨å¤±è´¥
- å®éªŒä»ä¼šç»§ç»­æ‰§è¡Œ
- æ˜¾ç¤ºè­¦å‘Šä¿¡æ¯
- ä¸å½±å“å®éªŒç»“æœ

### æ•°æ®æ”¶é›†å¤±è´¥
- è·³è¿‡æ— æ³•æ”¶é›†çš„èŠ‚ç‚¹
- æ”¶é›†å¯ç”¨èŠ‚ç‚¹çš„æ•°æ®
- è®°å½•å¤±è´¥åŸå› 

## ğŸ” æ•…éšœæ’æŸ¥

### é—®é¢˜1: SSH è¿æ¥å¤±è´¥

**ç—‡çŠ¶ï¼š**
```
âœ— Failed to create directory on hadoop002
```

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# æµ‹è¯• SSH è¿æ¥
ssh hadoop002 "echo test"

# æ£€æŸ¥ SSH å¯†é’¥
ls -la ~/.ssh/

# é‡æ–°é…ç½®å…å¯†ç™»å½•
ssh-copy-id hadoop002
```

### é—®é¢˜2: ç›‘æ§è¿›ç¨‹æ— æ³•å¯åŠ¨

**ç—‡çŠ¶ï¼š**
```
âš  Could not verify monitoring process on hadoop002
```

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# æ£€æŸ¥è¿œç¨‹èŠ‚ç‚¹ä¸Šçš„è„šæœ¬æƒé™
ssh hadoop002 "ls -la ~/monitoring/"

# æ‰‹åŠ¨æµ‹è¯•è„šæœ¬æ‰§è¡Œ
ssh hadoop002 "~/monitoring/collect_metrics.sh hadoop002 1"
```

### é—®é¢˜3: æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨

**ç—‡çŠ¶ï¼š**
```
âš  No monitoring data found on hadoop002
```

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# æ£€æŸ¥è¿œç¨‹æ–‡ä»¶
ssh hadoop002 "ls -la ~/monitoring/"

# æŸ¥çœ‹è„šæœ¬è¾“å‡ºç›®å½•
ssh hadoop002 "ls -la ~/monitoring/system_metrics/"
```

### é—®é¢˜4: ç£ç›˜ç©ºé—´ä¸è¶³

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# æ£€æŸ¥æœ¬åœ°ç£ç›˜ç©ºé—´
df -h .

# æ£€æŸ¥è¿œç¨‹èŠ‚ç‚¹ç©ºé—´
ssh hadoop002 "df -h ~"
ssh hadoop003 "df -h ~"

# æ¸…ç†æ—§æ•°æ®
rm -f system_metrics/*.csv.old
```

## ğŸ“ˆ æ•°æ®åˆ†æ

### æŸ¥çœ‹æ”¶é›†çš„ç›‘æ§æ•°æ®

```bash
# æŸ¥çœ‹æ–‡ä»¶åˆ—è¡¨
ls -lh system_metrics/

# æŸ¥çœ‹æ•°æ®å¤´éƒ¨
head -n 5 system_metrics/hadoop002_*.csv

# ç»Ÿè®¡æ•°æ®è¡Œæ•°
wc -l system_metrics/*.csv
```

### åˆ†æèŠ‚ç‚¹æ€§èƒ½

```bash
# hadoop002 çš„å¹³å‡ CPU ä½¿ç”¨ç‡
awk -F',' 'NR>1 {sum+=$3; count++} END {print "å¹³å‡CPU:", sum/count"%"}' \
    system_metrics/hadoop002_*.csv

# hadoop003 çš„æœ€å¤§å†…å­˜ä½¿ç”¨
awk -F',' 'NR>1 {if($4>max) max=$4} END {print "æœ€å¤§å†…å­˜:", max"MB"}' \
    system_metrics/hadoop003_*.csv
```

### ä½¿ç”¨ Python åˆ†æ

```python
import pandas as pd
import glob

# è¯»å–æ‰€æœ‰èŠ‚ç‚¹æ•°æ®
files = glob.glob('system_metrics/hadoop*_*.csv')
dfs = [pd.read_csv(f) for f in files]
df = pd.concat(dfs, ignore_index=True)

# æŒ‰èŠ‚ç‚¹åˆ†ç»„ç»Ÿè®¡
stats = df.groupby('node_name').agg({
    'cpu_percent': ['mean', 'max'],
    'memory_percent': ['mean', 'max'],
    'load_avg': 'mean'
})

print(stats)
```

## ğŸ› ï¸ é«˜çº§é…ç½®

### ä¿®æ”¹ç›‘æ§é—´éš”

æ›´å¯†é›†çš„æ•°æ®é‡‡é›†ï¼ˆæ¯ 0.5 ç§’ï¼‰ï¼š
```bash
MONITOR_INTERVAL=0.5
```

æ›´ç¨€ç–çš„æ•°æ®é‡‡é›†ï¼ˆæ¯ 5 ç§’ï¼‰ï¼š
```bash
MONITOR_INTERVAL=5
```

### è‡ªå®šä¹‰è¿œç¨‹ç›®å½•

```bash
REMOTE_MONITOR_DIR="/opt/monitoring"
```

### ä¿®æ”¹ Slowstart å‚æ•°èŒƒå›´

```bash
SLOWSTART_VALUES=(0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0)
```

## ğŸ“ æœ€ä½³å®è·µ

1. **å®éªŒå‰æ£€æŸ¥**
   - ç¡®è®¤æ‰€æœ‰èŠ‚ç‚¹ SSH è¿æ¥æ­£å¸¸
   - æ£€æŸ¥è¿œç¨‹èŠ‚ç‚¹ç£ç›˜ç©ºé—´å……è¶³
   - éªŒè¯ collect_metrics.sh è„šæœ¬å¯æ‰§è¡Œ

2. **å®éªŒä¸­ç›‘æ§**
   - å¯ä»¥åœ¨å¦ä¸€ä¸ªç»ˆç«¯å®æ—¶æŸ¥çœ‹è¿œç¨‹ç›‘æ§æ•°æ®
   ```bash
   ssh hadoop002 "tail -f ~/monitoring/system_metrics/hadoop002_*.csv"
   ```

3. **å®éªŒåå¤„ç†**
   - è„šæœ¬å·²è‡ªåŠ¨åœæ­¢ç›‘æ§å’Œæ”¶é›†æ•°æ®
   - åŠæ—¶å¤‡ä»½é‡è¦çš„å®éªŒç»“æœ
   - å¯é€‰æ‹©æ€§æ¸…ç†è¿œç¨‹èŠ‚ç‚¹çš„ç›‘æ§æ–‡ä»¶

4. **æ•°æ®ç®¡ç†**
   - ä½¿ç”¨æ—¶é—´æˆ³è¯†åˆ«ä¸åŒæ‰¹æ¬¡çš„å®éªŒ
   - å®šæœŸå¤‡ä»½ system_metrics/ ç›®å½•
   - å»ºç«‹å®éªŒæ—¥å¿—è®°å½•ä¹ æƒ¯

## ğŸ”„ ä¸æ‰‹åŠ¨æµç¨‹çš„å¯¹æ¯”

### æ‰‹åŠ¨æµç¨‹ï¼ˆæ—§æ–¹å¼ï¼‰
```bash
# 1. æ‰‹åŠ¨éƒ¨ç½²è„šæœ¬åˆ°æ¯ä¸ªèŠ‚ç‚¹
ssh hadoop002 "mkdir -p ~/monitoring"
scp scripts/collect_metrics.sh hadoop002:~/monitoring/
ssh hadoop003 "mkdir -p ~/monitoring"
scp scripts/collect_metrics.sh hadoop003:~/monitoring/

# 2. æ‰‹åŠ¨å¯åŠ¨ç›‘æ§
ssh hadoop002 "cd ~/monitoring && nohup ./collect_metrics.sh hadoop002 1 &"
ssh hadoop003 "cd ~/monitoring && nohup ./collect_metrics.sh hadoop003 1 &"

# 3. è¿è¡Œå®éªŒ
./scripts/batch_experiment.sh /mr_input_5gb /mr_output

# 4. æ‰‹åŠ¨åœæ­¢ç›‘æ§
ssh hadoop002 "pkill -f collect_metrics.sh"
ssh hadoop003 "pkill -f collect_metrics.sh"

# 5. æ‰‹åŠ¨æ”¶é›†æ•°æ®
scp hadoop002:~/monitoring/hadoop002*.csv ./system_metrics/
scp hadoop003:~/monitoring/hadoop003*.csv ./system_metrics/
```

### è‡ªåŠ¨åŒ–æµç¨‹ï¼ˆæ–°æ–¹å¼ï¼‰
```bash
# ä¸€é”®å®Œæˆæ‰€æœ‰æ“ä½œ
./scripts/batch_experiment.sh /mr_input_5gb /mr_output
```

**ä¼˜åŠ¿ï¼š**
- âœ… å‡å°‘äººå·¥æ“ä½œæ­¥éª¤
- âœ… é¿å…é—å¿˜åœæ­¢ç›‘æ§è¿›ç¨‹
- âœ… è‡ªåŠ¨åŒ–æ•°æ®æ”¶é›†ï¼Œå‡å°‘é”™è¯¯
- âœ… ç»Ÿä¸€çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è¾“å‡º
- âœ… æ”¯æŒå¤šèŠ‚ç‚¹æ‰¹é‡æ“ä½œ

## ğŸ†˜ å¸¸è§é—®é¢˜

**Q: å¦‚æœåªæƒ³ç›‘æ§ä¸€ä¸ªèŠ‚ç‚¹æ€ä¹ˆåŠï¼Ÿ**

A: ä¿®æ”¹èŠ‚ç‚¹åˆ—è¡¨ï¼š
```bash
REMOTE_NODES=("hadoop002")
```

**Q: å¯ä»¥åœ¨å®éªŒè¿›è¡Œä¸­é€”æ·»åŠ ç›‘æ§å—ï¼Ÿ**

A: å½“å‰ç‰ˆæœ¬ä¸æ”¯æŒã€‚ç›‘æ§å¿…é¡»åœ¨å®éªŒå¼€å§‹å‰å¯åŠ¨ã€‚

**Q: å¦‚ä½•æŸ¥çœ‹æŸä¸ªèŠ‚ç‚¹çš„å®æ—¶ç›‘æ§çŠ¶æ€ï¼Ÿ**

A: ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š
```bash
ssh hadoop002 "ps aux | grep collect_metrics"
ssh hadoop002 "tail -f ~/monitoring/system_metrics/hadoop002_*.csv"
```

**Q: ç›‘æ§æ•°æ®ä¼šå ç”¨å¤šå°‘ç©ºé—´ï¼Ÿ**

A: å–å†³äºå®éªŒæ—¶é•¿ã€‚é€šå¸¸æ¯å°æ—¶çº¦ 10-50MB æ¯èŠ‚ç‚¹ã€‚

**Q: å¦‚æœå®éªŒä¸­é€”å¤±è´¥ï¼Œç›‘æ§è¿›ç¨‹ä¼šè‡ªåŠ¨åœæ­¢å—ï¼Ÿ**

A: ä¸ä¼šã€‚ä½†è„šæœ¬åœ¨ Phase 3 ä¼šè‡ªåŠ¨åœæ­¢æ‰€æœ‰ç›‘æ§è¿›ç¨‹ã€‚å¦‚æœè„šæœ¬å¼‚å¸¸é€€å‡ºï¼Œéœ€è¦æ‰‹åŠ¨åœæ­¢ï¼š
```bash
ssh hadoop002 "pkill -f collect_metrics"
ssh hadoop003 "pkill -f collect_metrics"
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [multi_node_monitoring_usage.md](./multi_node_monitoring_usage.md) - æ‰‹åŠ¨å¤šèŠ‚ç‚¹ç›‘æ§æµç¨‹
- [MULTI_NODE_USAGE.md](./MULTI_NODE_USAGE.md) - å¤šèŠ‚ç‚¹æ€§èƒ½ç›‘æµ‹åŸºç¡€
- [README.md](../readme.md) - é¡¹ç›®ä¸»æ–‡æ¡£

---

**åˆ›å»ºæ—¥æœŸï¼š** 2025-11-26  
**é€‚ç”¨ç‰ˆæœ¬ï¼š** batch_experiment.sh v2.0 (è‡ªåŠ¨åŒ–å¤šèŠ‚ç‚¹ç›‘æ§ç‰ˆ)
